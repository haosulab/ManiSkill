# Sim2Real

For sim2real one typically needs to align dynamics and visual data. ManiSkill provides a few utilities to help minimize the amount of extra code you need to write and streamline the process. A pre-requisite to making sim2real environments in this tutorial is to first learn how to create simulation tasks in the [custom tasks tutorial](./custom_tasks/intro.md).


A real environment interface is like any other simulation gym environment and has nearly the same interface as simulation environmnets with a few differences. 

```python
import gymnasium as gym
from your_environment import YourEnvironment
from mani_skill.envs.real_env import RealEnv
sim_env = gym.make("YourEnvironment", obs_mode="rgb")
# you can also skip using gym and just do sim_env = YourEnvironment(obs_mode="rgb")
real_env = RealEnv(sim_env=sim_env, agent_cls=YourCustomRealRobotClass)
# resets the environment. Normally this would also
# initialize objects in the scene but since this is a real environment this will only
# reset the robot and/or sensors to initial states. The human must reset objects instead!
obs, info = real_env.reset()

for _ in range(100):
    action = real_env.action_space.sample() # same as your simulation environment action space
    # the real environment controller is the exact same as your simulation environment controller and reduces dynamics gaps
    obs, reward, terminated, truncated, info = real_env.step(action)
    # for any visual observation data it will now be generated by real sensors
    # rewards are by default TODO?
```

The simplest process is to first build an environment/task in simulation first, then to create a `RealEnv` object that uses the simulation environment to setup the real robot, controllers, sensors etc. accordingly. 

## Dynamics Alignment

If you are looking to 


## Recording Real World Episodes

TODO: use record episode still

## Applying Wrappers in Sim to Real Environments

Often times during RL / IL workflows you will have various useful environment wrappers to modify the aspects such as observations (e.g. to combine rgb and depth images) or actions (e.g. to apply an action sequence). Whatever wrappers you use for the simulation environment can also be applied to the real environment by simply appyling them to the sim environment before passing it into the `RealEnv` constructor.

```python
from mani_skill.envs.real_env import RealEnv
from mani_skill.utils.wrappers.flatten import FlattenRGBDObservationWrapper

wrappers = [FlattenRGBDObservationWrapper]
sim_env = gym.make("YourEnvironment", obs_mode="rgb")
for wrapper in wrappers:
    sim_env = wrapper(sim_env)
real_env = RealEnv(sim_env=sim_env, agent=YourCustomRealRobotClass)
```


## Customizing Real Environments More

By default the `RealEnv` class will infer and setup the observation and controllers as best as possible. However it is possible you might have specific use-cases such as custom real world controller code different from the simulation controller or modifications to the observation space.

You can either write your own code or create a class that inherits from `RealEnv` and overrides the behaviors as needed. To change observation data just change the `get_obs` function and to change the controller/actions just override the `_step_action` function.


```python
class MyCustomRealEnv(RealEnv):
    def _step_action(self, action):
        # custom real world controller code
        pass

    def get_obs(self, info):
        # change the observation space
        return super().get_obs(info)
```



