{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dependencies/setup\n",
    "Installs all the necessary dependencies as well as setups files."
   ],
   "metadata": {
    "id": "Z-iB8IwuoMRk"
   },
   "id": "Z-iB8IwuoMRk"
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir -p /usr/share/vulkan/icd.d\n",
    "!wget -q https://raw.githubusercontent.com/haosulab/ManiSkill2/main/docker/nvidia_icd.json\n",
    "!wget -q https://raw.githubusercontent.com/haosulab/ManiSkill2/main/docker/10_nvidia.json\n",
    "!mv nvidia_icd.json /usr/share/vulkan/icd.d\n",
    "!mv 10_nvidia.json /usr/share/glvnd/egl_vendor.d/10_nvidia.json\n",
    "# dependencies\n",
    "!apt-get install -y --no-install-recommends libvulkan-dev\n",
    "!pip install git+https://github.com/arnavg115/ManiSkill2.git\n",
    "!pip install --upgrade --no-cache-dir gdown\n",
    "!pip install diffusers wandb"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkv9qmTyrKDR",
    "outputId": "930d2f96-f9fc-4722-8420-b52fa58f24ed"
   },
   "id": "lkv9qmTyrKDR",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libvulkan1\n",
      "Recommended packages:\n",
      "  mesa-vulkan-drivers | vulkan-icd\n",
      "The following NEW packages will be installed:\n",
      "  libvulkan-dev libvulkan1\n",
      "0 upgraded, 2 newly installed, 0 to remove and 30 not upgraded.\n",
      "Need to get 1,020 kB of archives.\n",
      "After this operation, 17.2 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan-dev amd64 1.3.204.1-2 [892 kB]\n",
      "Fetched 1,020 kB in 2s (414 kB/s)\n",
      "Selecting previously unselected package libvulkan1:amd64.\n",
      "(Reading database ... 121658 files and directories currently installed.)\n",
      "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
      "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
      "Selecting previously unselected package libvulkan-dev:amd64.\n",
      "Preparing to unpack .../libvulkan-dev_1.3.204.1-2_amd64.deb ...\n",
      "Unpacking libvulkan-dev:amd64 (1.3.204.1-2) ...\n",
      "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
      "Setting up libvulkan-dev:amd64 (1.3.204.1-2) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "Collecting git+https://github.com/arnavg115/ManiSkill2.git\n",
      "  Cloning https://github.com/arnavg115/ManiSkill2.git to /tmp/pip-req-build-nx9dm2lz\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/arnavg115/ManiSkill2.git /tmp/pip-req-build-nx9dm2lz\n",
      "  Resolved https://github.com/arnavg115/ManiSkill2.git to commit d7e90358ee5b28e969eb254b0108bb925f8fd8a9\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy<1.24 in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (1.11.4)\n",
      "Collecting gymnasium>=0.28.1 (from mani_skill2==0.6.0)\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sapien==3.0.0.dev0 (from mani_skill2==0.6.0)\n",
      "  Downloading sapien-3.0.0.dev0-cp310-cp310-manylinux2014_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (3.9.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (6.0.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (4.66.1)\n",
      "Collecting GitPython (from mani_skill2==0.6.0)\n",
      "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (0.9.0)\n",
      "Requirement already satisfied: gdown>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (4.7.3)\n",
      "Collecting transforms3d (from mani_skill2==0.6.0)\n",
      "  Downloading transforms3d-0.4.1-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (4.8.0.76)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from mani_skill2==0.6.0) (2.31.6)\n",
      "Collecting trimesh (from mani_skill2==0.6.0)\n",
      "  Downloading trimesh-4.0.10-py3-none-any.whl (689 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.1/689.1 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rtree (from mani_skill2==0.6.0)\n",
      "  Downloading Rtree-1.2.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (535 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m535.2/535.2 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.22 in /usr/local/lib/python3.10/dist-packages (from sapien==3.0.0.dev0->mani_skill2==0.6.0) (2.31.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sapien==3.0.0.dev0->mani_skill2==0.6.0) (4.9.4)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from sapien==3.0.0.dev0->mani_skill2==0.6.0) (3.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.6.0->mani_skill2==0.6.0) (3.13.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.6.0->mani_skill2==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.6.0->mani_skill2==0.6.0) (4.11.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->mani_skill2==0.6.0) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->mani_skill2==0.6.0) (4.5.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.1->mani_skill2==0.6.0)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython->mani_skill2==0.6.0)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->mani_skill2==0.6.0) (9.4.0)\n",
      "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from imageio->mani_skill2==0.6.0) (0.4.9)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from imageio->mani_skill2==0.6.0) (5.9.5)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython->mani_skill2==0.6.0)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->sapien==3.0.0.dev0->mani_skill2==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->sapien==3.0.0.dev0->mani_skill2==0.6.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->sapien==3.0.0.dev0->mani_skill2==0.6.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->sapien==3.0.0.dev0->mani_skill2==0.6.0) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.6.0->mani_skill2==0.6.0) (2.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg->imageio->mani_skill2==0.6.0) (67.7.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22->sapien==3.0.0.dev0->mani_skill2==0.6.0) (1.7.1)\n",
      "Building wheels for collected packages: mani_skill2\n",
      "  Building wheel for mani_skill2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mani_skill2: filename=mani_skill2-0.6.0-py3-none-any.whl size=12012240 sha256=1228d545610cab5ddf46b7fbdd84df8db336f89419ea38a131293beed302bc1d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tvhg3ugd/wheels/1e/95/3f/a14059058deb304173a0da5324e81e4ef30ff2e1858476a4c7\n",
      "Successfully built mani_skill2\n",
      "Installing collected packages: farama-notifications, trimesh, transforms3d, smmap, rtree, gymnasium, sapien, gitdb, GitPython, mani_skill2\n",
      "Successfully installed GitPython-3.1.41 farama-notifications-0.0.4 gitdb-4.0.11 gymnasium-0.29.1 mani_skill2-0.6.0 rtree-1.2.0 sapien-3.0.0.dev0 smmap-5.0.1 transforms3d-0.4.1 trimesh-4.0.10\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
      "Collecting gdown\n",
      "  Downloading gdown-5.0.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: gdown\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.7.3\n",
      "    Uninstalling gdown-4.7.3:\n",
      "      Successfully uninstalled gdown-4.7.3\n",
      "Successfully installed gdown-5.0.0\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.25.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.20.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.41)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2023.11.17)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Installing collected packages: setproctitle, sentry-sdk, docker-pycreds, wandb, diffusers\n",
      "Successfully installed diffusers-0.25.1 docker-pycreds-0.4.0 sentry-sdk-1.39.2 setproctitle-1.3.3 wandb-0.16.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Diffusion Policy Using Maniskill-2\n",
    "This notebook implements [diffusion policy](https://diffusion-policy.cs.columbia.edu/) using the environments in ManiSkill2. This notebook uses code from the example jupyter notebook found [here](https://colab.research.google.com/drive/1gxdkgRVfM55zihY9TFLja97cSVZOZq2B?usp=sharing)."
   ],
   "metadata": {
    "id": "GXBFpmdOoQ8t"
   },
   "id": "GXBFpmdOoQ8t"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add0f79a-007d-4757-bf08-386238dce712",
   "metadata": {
    "id": "add0f79a-007d-4757-bf08-386238dce712",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123,
     "referenced_widgets": [
      "fd084bd8dc8a4508afbe5b7107520a1c",
      "940512086c2e4aa1b81b92b638789bc5",
      "20bdab34ad2e4ab2a192d8e030809e35",
      "d4181176128c4824bd26a3f4fd3268bb",
      "57a93708c09846a6aa9d384e02a68df6",
      "cd4a83f268d44441903f4bf331417816",
      "5906e7f09aec4d4d863a2d9b67b2eaf9",
      "f700efb0a581444ca2d6a5014be0f255",
      "142dea6236f2403b8c706c2602488621",
      "33022d4def8e4461a1d552c2a80b9844",
      "596aa3c51c30441f91c164d6312e7c5f"
     ]
    },
    "outputId": "46a99ffd-6aaa-4223-a3b2-42d8c95680ed"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sapien/wrapper/pinocchio_model.py:281: UserWarning: pinnochio package is not installed, fallback to built-in pinocchio\n",
      "  warnings.warn(\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd084bd8dc8a4508afbe5b7107520a1c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import mani_skill2.envs\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from mani_skill2.utils.io_utils import load_json\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "import math\n",
    "from mani_skill2.utils.wrappers import RecordEpisode\n",
    "from diffusers.optimization import get_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Initialize environment, download dataset, and define hyper parameters.\n"
   ],
   "metadata": {
    "id": "LifLr7HVo6y3"
   },
   "id": "LifLr7HVo6y3"
  },
  {
   "cell_type": "code",
   "source": [
    "env = \"LiftCube-v0\"  # @param [\"LiftCube-v0\", \"StackCube-v0\"]\n",
    "# @markdown If loss or evaluation metrics should be published to wandb.\n",
    "wandb = True  # @param {type:\"boolean\"}\n",
    "# @markdown How many observations are fed as part of the global condition\n",
    "obs_horizon = 2  # @param {type:\"integer\"}\n",
    "# @markdown How many predictions the model makes\n",
    "pred_horizon = 16  # @param {type:\"integer\"}\n",
    "# @markdown How many predictions are acted upon.\n",
    "action_horizon = 8  # @param {type:\"integer\"}\n",
    "batch_size = 256  # @param {type:\"integer\"}\n",
    "# @markdown How many epochs the model is trained on\n",
    "n_epochs = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"env\": env,\n",
    "    \"dataset\": f\"demos/v0/rigid_body/{env}/trajectory.state.pd_ee_delta_pose.h5\",\n",
    "    \"pred_horizon\": pred_horizon,\n",
    "    \"obs_horizon\": obs_horizon,\n",
    "    \"action_horizon\": action_horizon,\n",
    "    \"num_eval_eps\": 10,\n",
    "    \"eval_ep_len\": 100,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"wandb\": wandb,\n",
    "    \"n_epochs\": n_epochs,\n",
    "    \"dataset\": f\"demos/v0/rigid_body/{env}/trajectory.state.pd_ee_delta_pose.h5\",\n",
    "}"
   ],
   "metadata": {
    "id": "zOdt-rNtQNRd"
   },
   "id": "zOdt-rNtQNRd",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20737654-cdb7-4c14-8c53-b060d824ac3b",
   "metadata": {
    "id": "20737654-cdb7-4c14-8c53-b060d824ac3b"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    config[\"env\"],\n",
    "    obs_mode=\"state\",\n",
    "    control_mode=\"pd_ee_delta_pose\",\n",
    "    render_mode=\"cameras\",\n",
    "    enable_shadow=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @markdown Download preprocessed mani-skill2 trajectories\n",
    "!wget https://huggingface.co/datasets/a11g/maniskill2-replayed-trajectories/resolve/main/demos.zip?download=true -O demos.zip"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKY1e9tycHnN",
    "outputId": "36b784e0-3088-47e3-f36f-d3e53ed6af89"
   },
   "id": "zKY1e9tycHnN",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2024-01-24 17:46:51--  https://huggingface.co/datasets/a11g/maniskill2-replayed-trajectories/resolve/main/demos.zip?download=true\n",
      "Resolving huggingface.co (huggingface.co)... 13.33.33.55, 13.33.33.102, 13.33.33.110, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.33.33.55|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.huggingface.co/repos/fc/c9/fcc95cd9e7677aafe247b0d349c4e09c4db622091f64f08a66db3846092956ea/7af10271357a249edec6f14683f52e4cd6c5eb60261ed0b70696391444a0bf40?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27demos.zip%3B+filename%3D%22demos.zip%22%3B&response-content-type=application%2Fzip&Expires=1706377611&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNjM3NzYxMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZjL2M5L2ZjYzk1Y2Q5ZTc2NzdhYWZlMjQ3YjBkMzQ5YzRlMDljNGRiNjIyMDkxZjY0ZjA4YTY2ZGIzODQ2MDkyOTU2ZWEvN2FmMTAyNzEzNTdhMjQ5ZWRlYzZmMTQ2ODNmNTJlNGNkNmM1ZWI2MDI2MWVkMGI3MDY5NjM5MTQ0NGEwYmY0MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=MDkpLlUY-4Z4oLqIMR%7E1sPvdKordbzktxfCadtILaSbUpyf4ipOQfOuWl0M1M-1XdofgB4bW0A390jq2wrnlAFhSe5ix7LpJj4A6rgKeOnetfINUh17iKzIxg84tGCK7uZnw2Wxhi5ZoJK0wbPXtwJ9hv28qMiwsfRoD-bIcIHeuj-8PNMBFOSGDrFoGI32sutUOnjFQGQ6xHCy69uKmWFj-IvMu2Cwa1O2RgzLampdb1nAanR2791ryNDVO3BnDc-25FTNtT3T1HU9j7iUk2Hd0zN3OFU2C0XtHSWo7GpOburQsJxyJ3OHuXcdmBlKdWdWN9QG%7EC15lGPhP8Mgj7g__&Key-Pair-Id=KCD77M1F0VK2B [following]\n",
      "--2024-01-24 17:46:51--  https://cdn-lfs-us-1.huggingface.co/repos/fc/c9/fcc95cd9e7677aafe247b0d349c4e09c4db622091f64f08a66db3846092956ea/7af10271357a249edec6f14683f52e4cd6c5eb60261ed0b70696391444a0bf40?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27demos.zip%3B+filename%3D%22demos.zip%22%3B&response-content-type=application%2Fzip&Expires=1706377611&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNjM3NzYxMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZjL2M5L2ZjYzk1Y2Q5ZTc2NzdhYWZlMjQ3YjBkMzQ5YzRlMDljNGRiNjIyMDkxZjY0ZjA4YTY2ZGIzODQ2MDkyOTU2ZWEvN2FmMTAyNzEzNTdhMjQ5ZWRlYzZmMTQ2ODNmNTJlNGNkNmM1ZWI2MDI2MWVkMGI3MDY5NjM5MTQ0NGEwYmY0MD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=MDkpLlUY-4Z4oLqIMR%7E1sPvdKordbzktxfCadtILaSbUpyf4ipOQfOuWl0M1M-1XdofgB4bW0A390jq2wrnlAFhSe5ix7LpJj4A6rgKeOnetfINUh17iKzIxg84tGCK7uZnw2Wxhi5ZoJK0wbPXtwJ9hv28qMiwsfRoD-bIcIHeuj-8PNMBFOSGDrFoGI32sutUOnjFQGQ6xHCy69uKmWFj-IvMu2Cwa1O2RgzLampdb1nAanR2791ryNDVO3BnDc-25FTNtT3T1HU9j7iUk2Hd0zN3OFU2C0XtHSWo7GpOburQsJxyJ3OHuXcdmBlKdWdWN9QG%7EC15lGPhP8Mgj7g__&Key-Pair-Id=KCD77M1F0VK2B\n",
      "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 13.33.88.84, 13.33.88.54, 13.33.88.62, ...\n",
      "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|13.33.88.84|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 111214024 (106M) [application/zip]\n",
      "Saving to: ‘demos.zip?download=true’\n",
      "\n",
      "demos.zip?download= 100%[===================>] 106.06M  21.3MB/s    in 5.0s    \n",
      "\n",
      "2024-01-24 17:46:57 (21.3 MB/s) - ‘demos.zip?download=true’ saved [111214024/111214024]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip demos"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSCmyA01rkd5",
    "outputId": "8808e92b-a7d9-4f9e-b1bc-ff33c9e3f28c"
   },
   "id": "fSCmyA01rkd5",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Archive:  demos.zip\n",
      "   creating: demos/\n",
      "   creating: demos/v0/\n",
      "   creating: demos/v0/rigid_body/\n",
      "   creating: demos/v0/rigid_body/LiftCube-v0/\n",
      "  inflating: demos/v0/rigid_body/LiftCube-v0/trajectory.json  \n",
      "  inflating: demos/v0/rigid_body/LiftCube-v0/trajectory.h5  \n",
      "  inflating: demos/v0/rigid_body/LiftCube-v0/trajectory.state.pd_ee_delta_pose.h5  \n",
      "  inflating: demos/v0/rigid_body/LiftCube-v0/trajectory.state.pd_ee_delta_pose.json  \n",
      "   creating: demos/v0/rigid_body/StackCube-v0/\n",
      "  inflating: demos/v0/rigid_body/StackCube-v0/trajectory.json  \n",
      "  inflating: demos/v0/rigid_body/StackCube-v0/trajectory.h5  \n",
      "  inflating: demos/v0/rigid_body/StackCube-v0/trajectory.state.pd_ee_delta_pose.h5  \n",
      "  inflating: demos/v0/rigid_body/StackCube-v0/trajectory.state.pd_ee_delta_pose.json  \n",
      "   creating: demos/v0/rigid_body/PickCube-v0/\n",
      "  inflating: demos/v0/rigid_body/PickCube-v0/trajectory.json  \n",
      "  inflating: demos/v0/rigid_body/PickCube-v0/trajectory.h5  \n",
      "  inflating: demos/v0/rigid_body/PickCube-v0/trajectory.state.pd_ee_delta_pose.h5  \n",
      "  inflating: demos/v0/rigid_body/PickCube-v0/trajectory.state.pd_ee_delta_pose.json  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#1. Define Dataset.\n",
    "The datset is defined here. Also defined are helper methods that prepare the data to be fed into the model. We feed the model actions of shape (B,obs_horizon, obs_space) and actions of shape (B, pred_horizon, pred_shape). B stands for the batch size. We then define a dataloader which is used during training."
   ],
   "metadata": {
    "id": "WqPjUeNPrXS4"
   },
   "id": "WqPjUeNPrXS4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f200e7e-7071-48a6-9885-ea285372f8c7",
   "metadata": {
    "id": "1f200e7e-7071-48a6-9885-ea285372f8c7"
   },
   "outputs": [],
   "source": [
    "def load_h5_data(data):\n",
    "    out = dict()\n",
    "    for k in data.keys():\n",
    "        if isinstance(data[k], h5py.Dataset):\n",
    "            out[k] = data[k][:]\n",
    "        else:\n",
    "            out[k] = load_h5_data(data[k])\n",
    "    return out\n",
    "\n",
    "\n",
    "def create_sample_indices(\n",
    "    episode_ends: np.ndarray,\n",
    "    sequence_length: int,\n",
    "    pad_before: int = 0,\n",
    "    pad_after: int = 0,\n",
    "):\n",
    "    indices = list()\n",
    "    for i in range(len(episode_ends)):\n",
    "        start_idx = 0\n",
    "        # if i > 0:\n",
    "        #     start_idx = episode_ends[i-1]\n",
    "        end_idx = episode_ends[i]\n",
    "        episode_length = end_idx - start_idx\n",
    "\n",
    "        min_start = -pad_before\n",
    "        max_start = episode_length - sequence_length + pad_after\n",
    "\n",
    "        # range stops one idx before end\n",
    "        for idx in range(min_start, max_start + 1):\n",
    "            buffer_start_idx = max(idx, 0) + start_idx\n",
    "            buffer_end_idx = min(idx + sequence_length, episode_length) + start_idx\n",
    "            start_offset = buffer_start_idx - (idx + start_idx)\n",
    "            end_offset = (idx + sequence_length + start_idx) - buffer_end_idx\n",
    "            sample_start_idx = 0 + start_offset\n",
    "            sample_end_idx = sequence_length - end_offset\n",
    "            indices.append(\n",
    "                [buffer_start_idx, buffer_end_idx, sample_start_idx, sample_end_idx, i]\n",
    "            )\n",
    "    indices = np.array(indices)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def sample_sequence(\n",
    "    data, seq_len, buffer_start_idx, buffer_end_idx, sample_start_idx, sample_end_idx, i\n",
    "):\n",
    "    sample = data[i][buffer_start_idx:buffer_end_idx]\n",
    "    if sample_start_idx > 0:\n",
    "        sample = np.insert(sample, 0, np.tile(sample[0], (sample_start_idx, 1)), axis=0)\n",
    "    if sample_end_idx < seq_len:\n",
    "        sample = np.insert(\n",
    "            sample, -1, np.tile(sample[-1], (seq_len - sample_end_idx, 1)), axis=0\n",
    "        )\n",
    "    return sample\n",
    "\n",
    "\n",
    "class ManiSkill2Dataset(Dataset):\n",
    "    def __init__(self, config, load_count=-1) -> None:\n",
    "        self.dataset_file = config[\"dataset\"]\n",
    "        # for details on how the code below works, see the\n",
    "        # quick start tutorial\n",
    "        self.data = h5py.File(config[\"dataset\"], \"r\")\n",
    "        json_path = config[\"dataset\"].replace(\".h5\", \".json\")\n",
    "        self.json_data = load_json(json_path)\n",
    "        self.episodes = self.json_data[\"episodes\"]\n",
    "\n",
    "        self.env_info = self.json_data[\"env_info\"]\n",
    "        self.env_id = self.env_info[\"env_id\"]\n",
    "        self.env_kwargs = self.env_info[\"env_kwargs\"]\n",
    "\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.total_frames = 0\n",
    "        if load_count == -1:\n",
    "            load_count = len(self.episodes)\n",
    "        for eps_id in tqdm(range(load_count)):\n",
    "            eps = self.episodes[eps_id]\n",
    "            trajectory = self.data[f\"traj_{eps['episode_id']}\"]\n",
    "            trajectory = load_h5_data(trajectory)\n",
    "\n",
    "            # we use :-1 here to ignore the last observation as that\n",
    "            # is the terminal observation which has no actions\n",
    "            self.observations.append(trajectory[\"obs\"][:-1])\n",
    "            self.actions.append(trajectory[\"actions\"])\n",
    "            # print(trajectory.keys())\n",
    "        ends = [action.shape[0] for action in self.actions]\n",
    "        self.action_space = self.actions[0].shape[-1]\n",
    "        self.obs_space = self.observations[0].shape[-1]\n",
    "\n",
    "        self.episode_ends = np.array(ends)\n",
    "        self.inds = create_sample_indices(\n",
    "            self.episode_ends,\n",
    "            config[\"pred_horizon\"],\n",
    "            config[\"obs_horizon\"] - 1,\n",
    "            config[\"action_horizon\"] - 1,\n",
    "        )\n",
    "        self.pred_horizon = config[\"pred_horizon\"]\n",
    "        self.obs_horizon = config[\"obs_horizon\"]\n",
    "\n",
    "        # self.rewards = np.vstack(self.rewards)\n",
    "\n",
    "    def get_state_stats(self):\n",
    "        arr = np.vstack(self.observations)\n",
    "        return np.mean(arr, axis=0), np.std(arr, axis=0) + 1e-6\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        action = sample_sequence(self.actions, self.pred_horizon, *self.inds[idx])\n",
    "        obs = sample_sequence(self.observations, self.pred_horizon, *self.inds[idx])\n",
    "\n",
    "        return torch.from_numpy(action).to(torch.float32), torch.from_numpy(\n",
    "            obs[: self.obs_horizon, :]\n",
    "        ).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d0ad18-fa1c-4819-86cc-7f1f266a50e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "66308e95ffdc4bf9bedde2f570c1534e",
      "1c7cf62dcc624c0da49fc20d28271d52",
      "3f57da70f70e4323878b91556d74ecea",
      "f7caff3265bb4c1c96eff7f77634869a",
      "58a109bd3c2c44c1922fc27f7572999e",
      "69a02ccc5c0943ad9dc5c48fe342184f",
      "be8f026f06fc44deb3e1febd5b8fb406",
      "11eae249a6ce42128c25f1fa033a8c09",
      "46bff44855044ac8b02f090700efcc0b",
      "454e1499fb6540519fde6b1accae0a7b",
      "da0bb340bd3e4548a622592680f1e08e"
     ]
    },
    "id": "62d0ad18-fa1c-4819-86cc-7f1f266a50e6",
    "outputId": "e6fdfce3-0087-463c-ac6f-bd91b138efaa"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66308e95ffdc4bf9bedde2f570c1534e"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "dataset = ManiSkill2Dataset(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a590c-a44f-4817-8803-362fcb156902",
   "metadata": {
    "id": "ff9a590c-a44f-4817-8803-362fcb156902"
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    # accelerate cpu-gpu transfer\n",
    "    pin_memory=True,\n",
    "    # don't kill worker process afte each epoch\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Defining the model\n",
    "This is taken from the original implementation and it implements a conditional u-net. The following descriptions come from the original notebook. We then instantiate the model and noise scheduler. We also define an EMA of the model parameters as well as a learning rate scheduler.\n",
    "\n",
    "The model works taking noise and running it through the diffusion process in order to come up with an optimal action. The observations are used as the global condition for the model similar to how text would be used in a diffusion model meant for Text to Image."
   ],
   "metadata": {
    "id": "mDxTAZa0sln4"
   },
   "id": "mDxTAZa0sln4"
  },
  {
   "cell_type": "code",
   "source": [
    "# @markdown ### **Network**\n",
    "# @markdown\n",
    "# @markdown Defines a 1D UNet architecture `ConditionalUnet1D`\n",
    "# @markdown as the noise prediction network\n",
    "# @markdown\n",
    "# @markdown Components\n",
    "# @markdown - `SinusoidalPosEmb` Positional encoding for the diffusion iteration k\n",
    "# @markdown - `Downsample1d` Strided convolution to reduce temporal resolution\n",
    "# @markdown - `Upsample1d` Transposed convolution to increase temporal resolution\n",
    "# @markdown - `Conv1dBlock` Conv1d --> GroupNorm --> Mish\n",
    "# @markdown - `ConditionalResidualBlock1D` Takes two inputs `x` and `cond`. \\\n",
    "# @markdown `x` is passed through 2 `Conv1dBlock` stacked together with residual connection.\n",
    "# @markdown `cond` is applied to `x` with [FiLM](https://arxiv.org/abs/1709.07871) conditioning.\n",
    "\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class Downsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Upsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Conv1dBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1d --> GroupNorm --> Mish\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                inp_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "            ),\n",
    "            nn.GroupNorm(n_groups, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ConditionalResidualBlock1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, cond_dim, kernel_size=3, n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "                Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
    "        # predicts per-channel scale and bias\n",
    "        cond_channels = out_channels * 2\n",
    "        self.out_channels = out_channels\n",
    "        self.cond_encoder = nn.Sequential(\n",
    "            nn.Mish(), nn.Linear(cond_dim, cond_channels), nn.Unflatten(-1, (-1, 1))\n",
    "        )\n",
    "\n",
    "        # make sure dimensions compatible\n",
    "        self.residual_conv = (\n",
    "            nn.Conv1d(in_channels, out_channels, 1)\n",
    "            if in_channels != out_channels\n",
    "            else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        \"\"\"\n",
    "        x : [ batch_size x in_channels x horizon ]\n",
    "        cond : [ batch_size x cond_dim]\n",
    "\n",
    "        returns:\n",
    "        out : [ batch_size x out_channels x horizon ]\n",
    "        \"\"\"\n",
    "        out = self.blocks[0](x)\n",
    "        embed = self.cond_encoder(cond)\n",
    "\n",
    "        embed = embed.reshape(embed.shape[0], 2, self.out_channels, 1)\n",
    "        scale = embed[:, 0, ...]\n",
    "        bias = embed[:, 1, ...]\n",
    "        out = scale * out + bias\n",
    "\n",
    "        out = self.blocks[1](out)\n",
    "        out = out + self.residual_conv(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionalUnet1D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        global_cond_dim,\n",
    "        diffusion_step_embed_dim=256,\n",
    "        down_dims=[256, 512, 1024],\n",
    "        kernel_size=5,\n",
    "        n_groups=8,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_dim: Dim of actions.\n",
    "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
    "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
    "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
    "        down_dims: Channel size for each UNet level.\n",
    "          The length of this array determines numebr of levels.\n",
    "        kernel_size: Conv kernel size\n",
    "        n_groups: Number of groups for GroupNorm\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        all_dims = [input_dim] + list(down_dims)\n",
    "        start_dim = down_dims[0]\n",
    "\n",
    "        dsed = diffusion_step_embed_dim\n",
    "        diffusion_step_encoder = nn.Sequential(\n",
    "            SinusoidalPosEmb(dsed),\n",
    "            nn.Linear(dsed, dsed * 4),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(dsed * 4, dsed),\n",
    "        )\n",
    "        cond_dim = dsed + global_cond_dim\n",
    "\n",
    "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
    "        mid_dim = all_dims[-1]\n",
    "        self.mid_modules = nn.ModuleList(\n",
    "            [\n",
    "                ConditionalResidualBlock1D(\n",
    "                    mid_dim,\n",
    "                    mid_dim,\n",
    "                    cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size,\n",
    "                    n_groups=n_groups,\n",
    "                ),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    mid_dim,\n",
    "                    mid_dim,\n",
    "                    cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size,\n",
    "                    n_groups=n_groups,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        down_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            down_modules.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        ConditionalResidualBlock1D(\n",
    "                            dim_in,\n",
    "                            dim_out,\n",
    "                            cond_dim=cond_dim,\n",
    "                            kernel_size=kernel_size,\n",
    "                            n_groups=n_groups,\n",
    "                        ),\n",
    "                        ConditionalResidualBlock1D(\n",
    "                            dim_out,\n",
    "                            dim_out,\n",
    "                            cond_dim=cond_dim,\n",
    "                            kernel_size=kernel_size,\n",
    "                            n_groups=n_groups,\n",
    "                        ),\n",
    "                        Downsample1d(dim_out) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        up_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            up_modules.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        ConditionalResidualBlock1D(\n",
    "                            dim_out * 2,\n",
    "                            dim_in,\n",
    "                            cond_dim=cond_dim,\n",
    "                            kernel_size=kernel_size,\n",
    "                            n_groups=n_groups,\n",
    "                        ),\n",
    "                        ConditionalResidualBlock1D(\n",
    "                            dim_in,\n",
    "                            dim_in,\n",
    "                            cond_dim=cond_dim,\n",
    "                            kernel_size=kernel_size,\n",
    "                            n_groups=n_groups,\n",
    "                        ),\n",
    "                        Upsample1d(dim_in) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        final_conv = nn.Sequential(\n",
    "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
    "            nn.Conv1d(start_dim, input_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.diffusion_step_encoder = diffusion_step_encoder\n",
    "        self.up_modules = up_modules\n",
    "        self.down_modules = down_modules\n",
    "        self.final_conv = final_conv\n",
    "\n",
    "        print(\n",
    "            \"number of parameters: {:e}\".format(\n",
    "                sum(p.numel() for p in self.parameters())\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        sample: torch.Tensor,\n",
    "        timestep,  # TODO: Union[torch.Tensor, float, int]\n",
    "        global_cond=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        x: (B,T,input_dim)\n",
    "        timestep: (B,) or int, diffusion step\n",
    "        global_cond: (B,global_cond_dim)\n",
    "        output: (B,T,input_dim)\n",
    "        \"\"\"\n",
    "        # (B,T,C)\n",
    "        sample = sample.moveaxis(-1, -2)\n",
    "        # (B,C,T)\n",
    "\n",
    "        # 1. time\n",
    "        timesteps = timestep\n",
    "        if not torch.is_tensor(timesteps):\n",
    "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
    "            timesteps = torch.tensor(\n",
    "                [timesteps], dtype=torch.long, device=sample.device\n",
    "            )\n",
    "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
    "            timesteps = timesteps[None].to(sample.device)\n",
    "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
    "        timesteps = timesteps.expand(sample.shape[0])\n",
    "\n",
    "        global_feature = self.diffusion_step_encoder(timesteps)\n",
    "\n",
    "        if global_cond is not None:\n",
    "            global_feature = torch.cat([global_feature, global_cond], axis=-1)\n",
    "\n",
    "        x = sample\n",
    "        h = []\n",
    "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        for mid_module in self.mid_modules:\n",
    "            x = mid_module(x, global_feature)\n",
    "\n",
    "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        # (B,C,T)\n",
    "        x = x.moveaxis(-1, -2)\n",
    "        # (B,T,C)\n",
    "        return x"
   ],
   "metadata": {
    "id": "_rb52toB_yRr",
    "cellView": "form"
   },
   "id": "_rb52toB_yRr",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "obs_horizon = config[\"obs_horizon\"]\n",
    "pred_horizon = config[\"pred_horizon\"]\n",
    "action_horizon = config[\"action_horizon\"]\n",
    "\n",
    "# observation and action dimensions corrsponding to\n",
    "# the output of PushTEnv\n",
    "obs_dim = dataset.obs_space\n",
    "action_dim = dataset.action_space\n",
    "\n",
    "# create network object\n",
    "noise_pred_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim, global_cond_dim=obs_dim * obs_horizon\n",
    ")\n",
    "\n",
    "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
    "num_diffusion_iters = config[\"num_diffusion_iters\"]\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule=\"squaredcos_cap_v2\",\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type=\"epsilon\",\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device(\"cuda\")\n",
    "_ = noise_pred_net.to(device)\n",
    "\n",
    "num_epochs = config[\"n_epochs\"]\n",
    "\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema = EMAModel(parameters=noise_pred_net.parameters(), power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=noise_pred_net.parameters(), lr=1e-4, weight_decay=1e-6\n",
    ")\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(dataloader) * num_epochs,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsctVugC_gB6",
    "outputId": "23275727-1ec6-428a-a7b6-885f3d062e91"
   },
   "id": "GsctVugC_gB6",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of parameters: 6.642305e+07\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Defining Evaluation Function\n",
    "Here we define code to be used to evaluate our model and guage it's success rate."
   ],
   "metadata": {
    "id": "L_-LD_iztdiM"
   },
   "id": "L_-LD_iztdiM"
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(model: ConditionalUnet1D, env, noise_scheduler, config, device):\n",
    "    r = []\n",
    "    s = []\n",
    "    model.eval()\n",
    "\n",
    "    for _ in range(config[\"num_eval_eps\"]):\n",
    "        obs, info = env.reset()\n",
    "        rewards = list()\n",
    "        obs_deque = collections.deque(\n",
    "            [obs] * config[\"obs_horizon\"], maxlen=config[\"obs_horizon\"]\n",
    "        )\n",
    "\n",
    "        steps = 0\n",
    "        while steps < config[\"eval_ep_len\"]:\n",
    "            obs_seq = np.stack(obs_deque)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                noisy_action = torch.randn(\n",
    "                    (1, config[\"pred_horizon\"], config[\"action_dim\"]),\n",
    "                    device=config[\"device\"],\n",
    "                )\n",
    "                obs = torch.from_numpy(obs_seq).to(device=device, dtype=torch.float32)\n",
    "                obs = obs.unsqueeze(0).flatten(1)\n",
    "                noise_scheduler.set_timesteps(config[\"num_diffusion_iters\"])\n",
    "                for k in noise_scheduler.timesteps:\n",
    "                    # predict noise\n",
    "                    noise_pred = model(sample=noisy_action, timestep=k, global_cond=obs)\n",
    "\n",
    "                    # inverse diffusion step (remove noise)\n",
    "                    noisy_action = noise_scheduler.step(\n",
    "                        model_output=noise_pred, timestep=k, sample=noisy_action\n",
    "                    ).prev_sample\n",
    "                actions = noisy_action[0].detach().to(device=\"cpu\").numpy()\n",
    "                start = config[\"obs_horizon\"] - 1\n",
    "                end = start + config[\"action_horizon\"]\n",
    "\n",
    "                for action in actions[start:end]:\n",
    "                    observation, reward, _, _, info = env.step(action)\n",
    "                    obs_deque.append(observation)\n",
    "                    # and reward/vis\n",
    "                    rewards.append(reward)\n",
    "                    steps += 1\n",
    "        s.append(info[\"success\"])\n",
    "        r.append(sum(rewards) / len(rewards))\n",
    "    model.train()\n",
    "    return s, r"
   ],
   "metadata": {
    "id": "fehJKGEzSASU"
   },
   "id": "fehJKGEzSASU",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Train function\n",
    "Here we define a training function for our model. This code also evaluates the model every `eval_interval`."
   ],
   "metadata": {
    "id": "w3vy01e-ttnG"
   },
   "id": "w3vy01e-ttnG"
  },
  {
   "cell_type": "code",
   "source": [
    "def train(\n",
    "    noise_pred_net: ConditionalUnet1D,\n",
    "    optimizer,\n",
    "    noise_scheduler,\n",
    "    dataloader,\n",
    "    ema,\n",
    "    lr_scheduler,\n",
    "    env,\n",
    "    config: dict,\n",
    "    device: str,\n",
    "):\n",
    "    if config[\"wandb\"]:\n",
    "        import wandb\n",
    "\n",
    "        def log_fn(output: dict):\n",
    "            wandb.log(output)\n",
    "\n",
    "    log = {}\n",
    "    noise_pred_net.train()\n",
    "    for epoch in tqdm(range(config[\"n_epochs\"])):\n",
    "        epoch_loss = []\n",
    "        for batch in dataloader:\n",
    "            obs = batch[1].to(device=device)\n",
    "            action = batch[0].to(device=device)\n",
    "            B = obs.shape[0]\n",
    "            obs_cond = obs[:, : config[\"obs_horizon\"], :]\n",
    "            # (B, obs_horizon * obs_dim)\n",
    "            obs_cond = obs_cond.flatten(start_dim=1)\n",
    "            noise = torch.randn(action.shape, device=device)\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps, (B,), device=device\n",
    "            ).long()\n",
    "\n",
    "            # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_actions = noise_scheduler.add_noise(action, noise, timesteps)\n",
    "\n",
    "            # predict the noise residual\n",
    "            noise_pred = noise_pred_net(noisy_actions, timesteps, global_cond=obs_cond)\n",
    "\n",
    "            # L2 loss\n",
    "            loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "            # optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # step lr scheduler every batch\n",
    "            # this is different from standard pytorch behavior\n",
    "            lr_scheduler.step()\n",
    "            ema.step(noise_pred_net.parameters())\n",
    "\n",
    "            # logging\n",
    "            loss_cpu = loss.item()\n",
    "            epoch_loss.append(loss_cpu)\n",
    "\n",
    "        if epoch % config[\"eval_interval\"] == 0 and epoch > 0:\n",
    "            ema_noise_pred_net = noise_pred_net\n",
    "            ema.copy_to(ema_noise_pred_net.parameters())\n",
    "            log[\"training/epoch_loss_mean\"] = np.mean(np.array(epoch_loss))\n",
    "            log[\"training/epoch_loss_std\"] = np.std(np.array(epoch_loss))\n",
    "            s, r = evaluate(\n",
    "                ema_noise_pred_net, env, noise_scheduler, config, config[\"device\"]\n",
    "            )\n",
    "            log[\"eval/success_rate\"] = sum(np.array(s)) / len(s)\n",
    "            log[\"eval/reward_avg\"] = np.mean(np.array(r))\n",
    "            log[\"eval/reward_std\"] = np.std(np.array(r))\n",
    "            if config[\"wandb\"]:\n",
    "                log_fn(log)\n",
    "    ema_noise_pred_net = noise_pred_net\n",
    "    ema.copy_to(ema_noise_pred_net.parameters())"
   ],
   "metadata": {
    "id": "x89xU0J6R0hu"
   },
   "id": "x89xU0J6R0hu",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Training the model.\n",
    "This may take some time to train the model. If you selected wandb logging you will need to input your wandb api key here."
   ],
   "metadata": {
    "id": "BQbdDZnkuGQ6"
   },
   "id": "BQbdDZnkuGQ6"
  },
  {
   "cell_type": "code",
   "source": [
    "if config[\"wandb\"]:\n",
    "    wandb.init(\n",
    "        name=f\"maniskill2-{env_id}-{random.randint(0, 100000)}\",\n",
    "        group=f\"maniskill2-{env_id}\",\n",
    "        project=\"diffusion-policy\",\n",
    "        config={\n",
    "            \"n_epochs\": 10000,\n",
    "            \"obs_horizon\": 2,\n",
    "            \"eval_interval\": 1000,\n",
    "            \"num_eval_eps\": 10,\n",
    "            \"eval_ep_len\": 100,\n",
    "            \"pred_horizon\": 16,\n",
    "        },\n",
    "    )\n",
    "\n",
    "train(\n",
    "    noise_pred_net,\n",
    "    optimizer,\n",
    "    noise_scheduler,\n",
    "    dataloader,\n",
    "    ema,\n",
    "    lr_scheduler,\n",
    "    env,\n",
    "    config,\n",
    "    device,\n",
    ")"
   ],
   "metadata": {
    "id": "HDiiFnPjSyc_"
   },
   "id": "HDiiFnPjSyc_",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Render a Video\n",
    "Here we use ManiSkill2's record episode functionality to record a video of our model in action."
   ],
   "metadata": {
    "id": "gGzf2WVZuhp0"
   },
   "id": "gGzf2WVZuhp0"
  },
  {
   "cell_type": "code",
   "source": [
    "video_env = RecordEpisode(env, \"./videos\", info_on_video=True)\n",
    "evaluate(ema_noise_pred_net, video_env, noise_scheduler, config, config[\"device\"])\n",
    "video_env.flush_video()"
   ],
   "metadata": {
    "id": "gMXSAKppCs1B"
   },
   "id": "gMXSAKppCs1B",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "fd084bd8dc8a4508afbe5b7107520a1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_940512086c2e4aa1b81b92b638789bc5",
       "IPY_MODEL_20bdab34ad2e4ab2a192d8e030809e35",
       "IPY_MODEL_d4181176128c4824bd26a3f4fd3268bb"
      ],
      "layout": "IPY_MODEL_57a93708c09846a6aa9d384e02a68df6"
     }
    },
    "940512086c2e4aa1b81b92b638789bc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd4a83f268d44441903f4bf331417816",
      "placeholder": "​",
      "style": "IPY_MODEL_5906e7f09aec4d4d863a2d9b67b2eaf9",
      "value": ""
     }
    },
    "20bdab34ad2e4ab2a192d8e030809e35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f700efb0a581444ca2d6a5014be0f255",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_142dea6236f2403b8c706c2602488621",
      "value": 0
     }
    },
    "d4181176128c4824bd26a3f4fd3268bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33022d4def8e4461a1d552c2a80b9844",
      "placeholder": "​",
      "style": "IPY_MODEL_596aa3c51c30441f91c164d6312e7c5f",
      "value": " 0/0 [00:00&lt;?, ?it/s]"
     }
    },
    "57a93708c09846a6aa9d384e02a68df6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd4a83f268d44441903f4bf331417816": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5906e7f09aec4d4d863a2d9b67b2eaf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f700efb0a581444ca2d6a5014be0f255": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "142dea6236f2403b8c706c2602488621": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33022d4def8e4461a1d552c2a80b9844": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "596aa3c51c30441f91c164d6312e7c5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "66308e95ffdc4bf9bedde2f570c1534e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c7cf62dcc624c0da49fc20d28271d52",
       "IPY_MODEL_3f57da70f70e4323878b91556d74ecea",
       "IPY_MODEL_f7caff3265bb4c1c96eff7f77634869a"
      ],
      "layout": "IPY_MODEL_58a109bd3c2c44c1922fc27f7572999e"
     }
    },
    "1c7cf62dcc624c0da49fc20d28271d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69a02ccc5c0943ad9dc5c48fe342184f",
      "placeholder": "​",
      "style": "IPY_MODEL_be8f026f06fc44deb3e1febd5b8fb406",
      "value": "100%"
     }
    },
    "3f57da70f70e4323878b91556d74ecea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11eae249a6ce42128c25f1fa033a8c09",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46bff44855044ac8b02f090700efcc0b",
      "value": 100
     }
    },
    "f7caff3265bb4c1c96eff7f77634869a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_454e1499fb6540519fde6b1accae0a7b",
      "placeholder": "​",
      "style": "IPY_MODEL_da0bb340bd3e4548a622592680f1e08e",
      "value": " 100/100 [00:00&lt;00:00, 435.27it/s]"
     }
    },
    "58a109bd3c2c44c1922fc27f7572999e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69a02ccc5c0943ad9dc5c48fe342184f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be8f026f06fc44deb3e1febd5b8fb406": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11eae249a6ce42128c25f1fa033a8c09": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46bff44855044ac8b02f090700efcc0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "454e1499fb6540519fde6b1accae0a7b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da0bb340bd3e4548a622592680f1e08e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}