####
args.num_iterations=3906 args.num_envs=512 args.num_eval_envs=8
args.minibatch_size=800 args.batch_size=25600 args.update_epochs=4
####
Epoch: 1, global_step=0
Evaluating
Evaluated 400 steps resulting in 8 episodes
eval_success_once_mean=0.0
eval_return_mean=2.8365252017974854
eval_episode_len_mean=50.0
eval_reward_mean=0.05673050507903099
eval_success_at_end_mean=0.0
model saved to runs/PickCubeMatched3_panda_jv_ppo_rgb_3/ckpt_1.pt
SPS: 3825
Epoch: 2, global_step=25600
SPS: 4812
Epoch: 3, global_step=51200
SPS: 5235
Epoch: 4, global_step=76800
SPS: 5472
Epoch: 5, global_step=102400
SPS: 5613
Epoch: 6, global_step=128000
SPS: 5707
Epoch: 7, global_step=153600
SPS: 5770
Epoch: 8, global_step=179200
SPS: 5815
Epoch: 9, global_step=204800
SPS: 5850
Epoch: 10, global_step=230400
SPS: 5879
Epoch: 11, global_step=256000
SPS: 5902
Epoch: 12, global_step=281600
SPS: 5921
Epoch: 13, global_step=307200
SPS: 5937
Epoch: 14, global_step=332800
SPS: 5946
Epoch: 15, global_step=358400
SPS: 5950
Epoch: 16, global_step=384000
SPS: 5952
Epoch: 17, global_step=409600
SPS: 5956
Epoch: 18, global_step=435200
SPS: 5958
Epoch: 19, global_step=460800
SPS: 5960
Epoch: 20, global_step=486400
SPS: 5962
Epoch: 21, global_step=512000
Evaluating
Evaluated 400 steps resulting in 8 episodes
eval_success_once_mean=0.0
eval_return_mean=15.301362991333008
eval_episode_len_mean=50.0
eval_reward_mean=0.30602726340293884
eval_success_at_end_mean=0.0
model saved to runs/PickCubeMatched3_panda_jv_ppo_rgb_3/ckpt_21.pt
SPS: 5819
Epoch: 22, global_step=537600
SPS: 5826
Epoch: 23, global_step=563200
SPS: 5832
Epoch: 24, global_step=588800
SPS: 5836
Epoch: 25, global_step=614400
SPS: 5839
Epoch: 26, global_step=640000
SPS: 5840
Epoch: 27, global_step=665600
SPS: 5842
Epoch: 28, global_step=691200
SPS: 5843
Epoch: 29, global_step=716800
SPS: 5844
Epoch: 30, global_step=742400
SPS: 5845
Epoch: 31, global_step=768000
SPS: 5846
Epoch: 32, global_step=793600
SPS: 5847
Epoch: 33, global_step=819200
SPS: 5848
Epoch: 34, global_step=844800
SPS: 5847
Epoch: 35, global_step=870400
SPS: 5847
Epoch: 36, global_step=896000
SPS: 5846
Epoch: 37, global_step=921600
SPS: 5844
Epoch: 38, global_step=947200
SPS: 5841
Epoch: 39, global_step=972800
SPS: 5836
Epoch: 40, global_step=998400
SPS: 5829
Epoch: 41, global_step=1024000
Evaluating
Evaluated 400 steps resulting in 8 episodes
eval_success_once_mean=0.125
eval_return_mean=20.156147003173828
eval_episode_len_mean=50.0
eval_reward_mean=0.4031229615211487
eval_success_at_end_mean=0.125
model saved to runs/PickCubeMatched3_panda_jv_ppo_rgb_3/ckpt_41.pt
SPS: 5752
Epoch: 42, global_step=1049600
SPS: 5746
Epoch: 43, global_step=1075200
SPS: 5740
Epoch: 44, global_step=1100800
SPS: 5733
Epoch: 45, global_step=1126400
SPS: 5727
Epoch: 46, global_step=1152000
SPS: 5720
Epoch: 47, global_step=1177600
SPS: 5712
Epoch: 48, global_step=1203200
SPS: 5706
Epoch: 49, global_step=1228800
SPS: 5701
Epoch: 50, global_step=1254400
SPS: 5694
Epoch: 51, global_step=1280000
SPS: 5687
Epoch: 52, global_step=1305600
SPS: 5679
Epoch: 53, global_step=1331200
SPS: 5671
Epoch: 54, global_step=1356800
SPS: 5664
Epoch: 55, global_step=1382400
SPS: 5655
Epoch: 56, global_step=1408000
SPS: 5647
Epoch: 57, global_step=1433600
SPS: 5639
Epoch: 58, global_step=1459200
SPS: 5631
Epoch: 59, global_step=1484800
SPS: 5624
Epoch: 60, global_step=1510400
SPS: 5617
Epoch: 61, global_step=1536000
Evaluating
Evaluated 400 steps resulting in 8 episodes
eval_success_once_mean=0.0
eval_return_mean=19.750770568847656
eval_episode_len_mean=50.0
eval_reward_mean=0.3950154185295105
eval_success_at_end_mean=0.0
model saved to runs/PickCubeMatched3_panda_jv_ppo_rgb_3/ckpt_61.pt
SPS: 5567
Epoch: 62, global_step=1561600
SPS: 5561
Epoch: 63, global_step=1587200
SPS: 5554
Epoch: 64, global_step=1612800
SPS: 5547
Epoch: 65, global_step=1638400
SPS: 5541
Epoch: 66, global_step=1664000
SPS: 5535
Epoch: 67, global_step=1689600
SPS: 5529
Epoch: 68, global_step=1715200
SPS: 5523
Epoch: 69, global_step=1740800
SPS: 5516
Epoch: 70, global_step=1766400
SPS: 5510
Epoch: 71, global_step=1792000
SPS: 5503
Epoch: 72, global_step=1817600
SPS: 5495
Epoch: 73, global_step=1843200
SPS: 5497
Epoch: 74, global_step=1868800
SPS: 5490
Epoch: 75, global_step=1894400
SPS: 5482
Epoch: 76, global_step=1920000
SPS: 5473
Epoch: 77, global_step=1945600
SPS: 5465
Epoch: 78, global_step=1971200
SPS: 5456
Epoch: 79, global_step=1996800
SPS: 5448
Epoch: 80, global_step=2022400
SPS: 5440
Epoch: 81, global_step=2048000
Evaluating
Evaluated 400 steps resulting in 8 episodes
eval_success_once_mean=0.25
eval_return_mean=22.846790313720703
eval_episode_len_mean=50.0
eval_reward_mean=0.4569357931613922
eval_success_at_end_mean=0.125
model saved to runs/PickCubeMatched3_panda_jv_ppo_rgb_3/ckpt_81.pt
SPS: 5400
Epoch: 82, global_step=2073600
SPS: 5391
Epoch: 83, global_step=2099200
SPS: 5382
Epoch: 84, global_step=2124800
SPS: 5374
Epoch: 85, global_step=2150400
SPS: 5365
Epoch: 86, global_step=2176000
SPS: 5356
Epoch: 87, global_step=2201600
SPS: 5346
Epoch: 88, global_step=2227200
SPS: 5337
Epoch: 89, global_step=2252800
SPS: 5328
Epoch: 90, global_step=2278400
SPS: 5319
Epoch: 91, global_step=2304000
SPS: 5311
Epoch: 92, global_step=2329600
SPS: 5302
Epoch: 93, global_step=2355200
SPS: 5293
Epoch: 94, global_step=2380800
SPS: 5285
Epoch: 95, global_step=2406400
SPS: 5276
Epoch: 96, global_step=2432000
SPS: 5268
Epoch: 97, global_step=2457600
SPS: 5260
Epoch: 98, global_step=2483200
SPS: 5252
Epoch: 99, global_step=2508800
SPS: 5244
Epoch: 100, global_step=2534400
SPS: 5235
Epoch: 101, global_step=2560000
Evaluating
Evaluated 400 steps resulting in 8 episodes
eval_success_once_mean=0.125
eval_return_mean=21.712778091430664
eval_episode_len_mean=50.0
eval_reward_mean=0.43425554037094116
eval_success_at_end_mean=0.0
model saved to runs/PickCubeMatched3_panda_jv_ppo_rgb_3/ckpt_101.pt
SPS: 5203
Epoch: 102, global_step=2585600
Traceback (most recent call last):
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/examples/baselines/ppo/ppo_rgb.py", line 440, in <module>
    next_obs, reward, terminations, truncations, infos = envs.step(action)
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/vector/wrappers/gymnasium.py", line 149, in step
    obs, infos = self.reset(options=dict(env_idx=env_idx))
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/vector/wrappers/gymnasium.py", line 94, in reset
    obs, info = self._env.reset(seed=seed, options=options)
  File "/home/woojeh/miniconda3/envs/icra2025/lib/python3.10/site-packages/gymnasium/core.py", line 515, in reset
    obs, info = self.env.reset(seed=seed, options=options)
  File "/home/woojeh/miniconda3/envs/icra2025/lib/python3.10/site-packages/gymnasium/core.py", line 467, in reset
    return self.env.reset(seed=seed, options=options)
  File "/home/woojeh/miniconda3/envs/icra2025/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py", line 61, in reset
    return self.env.reset(**kwargs)
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/envs/sapien_env.py", line 945, in reset
    obs = self.get_obs(info)
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/envs/sapien_env.py", line 524, in get_obs
    obs = self._get_obs_with_sensor_data(info)
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/envs/sapien_env.py", line 625, in _get_obs_with_sensor_data
    sensor_data=self._get_obs_sensor_data(apply_texture_transforms),
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/envs/sapien_env.py", line 616, in _get_obs_sensor_data
    torch.cuda.synchronize()
  File "/home/woojeh/miniconda3/envs/icra2025/lib/python3.10/site-packages/torch/cuda/__init__.py", line 954, in synchronize
    return torch._C._cuda_synchronize()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/examples/baselines/ppo/ppo_rgb.py", line 440, in <module>
    next_obs, reward, terminations, truncations, infos = envs.step(action)
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/vector/wrappers/gymnasium.py", line 149, in step
    obs, infos = self.reset(options=dict(env_idx=env_idx))
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/vector/wrappers/gymnasium.py", line 94, in reset
    obs, info = self._env.reset(seed=seed, options=options)
  File "/home/woojeh/miniconda3/envs/icra2025/lib/python3.10/site-packages/gymnasium/core.py", line 515, in reset
    obs, info = self.env.reset(seed=seed, options=options)
  File "/home/woojeh/miniconda3/envs/icra2025/lib/python3.10/site-packages/gymnasium/core.py", line 467, in reset
    return self.env.reset(seed=seed, options=options)
  File "/home/woojeh/miniconda3/envs/icra2025/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py", line 61, in reset
    return self.env.reset(**kwargs)
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/envs/sapien_env.py", line 945, in reset
    obs = self.get_obs(info)
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/envs/sapien_env.py", line 524, in get_obs
    obs = self._get_obs_with_sensor_data(info)
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/envs/sapien_env.py", line 625, in _get_obs_with_sensor_data
    sensor_data=self._get_obs_sensor_data(apply_texture_transforms),
  File "/home/woojeh/Documents/ICRA2025/ManiSkill/mani_skill/envs/sapien_env.py", line 616, in _get_obs_sensor_data
    torch.cuda.synchronize()
  File "/home/woojeh/miniconda3/envs/icra2025/lib/python3.10/site-packages/torch/cuda/__init__.py", line 954, in synchronize
    return torch._C._cuda_synchronize()
KeyboardInterrupt
